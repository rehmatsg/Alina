{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alina v3.0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6vsn5H4havejFDt9OtdQA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rehmatsg/Alina/blob/master/Alina-v3.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOrwXZZnm2gA"
      },
      "source": [
        "# Alina\n",
        "_V3.0_\n",
        "\n",
        "Welcome to Alina's Colab Repo. This is version 3.0\n",
        "\n",
        "Visit https://github.com/rehmatsg/Alina for more info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKK8iaxMnGyC"
      },
      "source": [
        "import spacy\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import urllib.request\n",
        "import re\n",
        "import string"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-7fDoxbncYm"
      },
      "source": [
        "Use the below cell to initialize Spacy, and other modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H_Y5FN2nac9"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm') ## Creates an instance of Natural Language Processor"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6bSS7LyWPAT"
      },
      "source": [
        "#### Load TF Model from path\n",
        "Below methods loads a model from path locally. But there is a catch, model can be loaded only once in a runtime in Google Colab (not tested this error locally)\n",
        "Source: https://colab.research.google.com/drive/1OHBedJv8aqg1hpeKlf5DBfPuVYGFZinO?usp=sharing#scrollTo=W1mVJBZOpMxY"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJYLGN8LWKap"
      },
      "source": [
        "def getModel(path, summary=False, error=True):\n",
        "  model = None\n",
        "  with tf.keras.utils.custom_object_scope({'custom_standardization': custom_standardization}):\n",
        "    model = tf.keras.models.load_model(path)  # Folder\n",
        "\n",
        "  if model is not None and summary:\n",
        "    model.summary()\n",
        "  elif model is None:\n",
        "    print(\"Unable to load model from path\")\n",
        "\n",
        "  return model\n",
        "\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(\n",
        "    stripped_html,\n",
        "    '[%s]' % re.escape(string.punctuation),\n",
        "    ''\n",
        "  )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo4RYQW1o0K0"
      },
      "source": [
        "#### Alina\n",
        "Here comes the main code. `Alina` class is the root of our AI. Create an instance `Alina`\n",
        "\n",
        "`alina = Alina(user_name, speak=true)`\n",
        "\n",
        "* `user_name` is User's name. This is required to make Alina look more natural.\n",
        "* Set `speak` argument to `True` if you want Alina to speak it's responses.\n",
        "---\n",
        "#### Classifier\n",
        "This is the model for text classifier. To use Alina's text classifier, we use this class. To get started, create an instance of Classifier\n",
        "\n",
        "`classifier = Classifier()`\n",
        "\n",
        "This may take some time because model has to be downloaded from GitHub repo first.\n",
        "\n",
        "Use the method `.predict()` for predicting text statement as positive, negative or neutral.\n",
        "Returns a numpy array. Prediction lies between 0 and 1. 0 for negative and 1 for positive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "code",
        "id": "ZJcdoxCzozuV"
      },
      "source": [
        "class Alina:\n",
        "  def __init__(self, username, speak):\n",
        "    self.name = username\n",
        "    self.speakAnswers = speak\n",
        "    self.classifier = Classifier()\n",
        "\n",
        "  def speak(text):\n",
        "    ## This method cannot work in Google Colab\n",
        "    ## Use PYTTSX3 for Text-to-Speech\n",
        "    ## Leaving it empty to use it only in IDLE or Jupyter Lab\n",
        "    return\n",
        "\n",
        "  ## This function ASK returns two variables\n",
        "  ## 1) Response (String): This is the actual response of Alina. This has to be shown to the user\n",
        "  ## 2) Quit (bool): Returns True if user has asked Alina to quit chat session\n",
        "  def ask(self):\n",
        "    what = input('Ask me anythin\\' ')\n",
        "    ## TODO\n",
        "    prediction = self.classifier.predict([what])\n",
        "    if (what == 'quit'):\n",
        "      return ('See you later, boss', True);\n",
        "    return (f'Your statement classified as ... {prediction}', False);\n",
        "\n",
        "class Classifier:\n",
        "  def __init__(self):\n",
        "    url = 'https://raw.githubusercontent.com/rehmatsg/Alina/master/text_classifier.zip' ## Official GitHub repo of Alina v3.0\n",
        "    urllib.request.urlretrieve(url, 'text_classifier.zip')\n",
        "    !unzip text_classifier.zip ## Unzip the .zip file of text_classifier model downloaded from GitHub repo\n",
        "    self.model = getModel('text_classifier')\n",
        "\n",
        "  def predict(self, statements):\n",
        "    return self.model.predict(statements)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANEayGebaWt2"
      },
      "source": [
        "# Run\n",
        "Collect all data required from user and create an instance of `Alina`. This is the section where we run Alina infinitely until a stop-word is used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Y6Y45PqoQw2"
      },
      "source": [
        "Not required, but makes it feel more natural when Alina uses your name in responses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d87DQ-yIoQSy",
        "outputId": "213a6ea0-d0f9-41c7-a884-8fd3450a4a7d"
      },
      "source": [
        "print('Hi there,\\nI\\'m Alina, a personal digital assistant.')\n",
        "# user = input('What\\'s your name? ')\n",
        "user = 'Rehmat'\n",
        "alina = Alina(user, speak=False)\n",
        "print(f'Hi, {user}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hi there,\n",
            "I'm Alina, a personal digital assistant.\n",
            "Archive:  text_classifier.zip\n",
            "replace __MACOSX/._text_classifier? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: __MACOSX/._text_classifier  \n",
            "  inflating: __MACOSX/text_classifier/._variables  \n",
            "  inflating: text_classifier/saved_model.pb  \n",
            "  inflating: __MACOSX/text_classifier/._saved_model.pb  \n",
            "  inflating: __MACOSX/text_classifier/._assets  \n",
            "  inflating: text_classifier/variables/variables.data-00000-of-00001  \n",
            "  inflating: __MACOSX/text_classifier/variables/._variables.data-00000-of-00001  \n",
            "  inflating: text_classifier/variables/variables.index  \n",
            "  inflating: __MACOSX/text_classifier/variables/._variables.index  \n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_vectorization (TextVect (None, 250)               0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 1)                 160033    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 160,033\n",
            "Trainable params: 160,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Hi, Rehmat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR6ZNROxn4qW"
      },
      "source": [
        "`while` block in the following cell runs Alina instance forever until a stopword is used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbcF1_Synw9O",
        "outputId": "dacaf5fd-5420-4fa2-87a8-7d3ea82c9717"
      },
      "source": [
        "while True:\n",
        "  response, quit = alina.ask()\n",
        "  print(response)\n",
        "  if (quit):\n",
        "    break"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ask me anythin' The movie was terrible\n",
            "Your statement classified as ... [[0.3853296]]\n",
            "Ask me anythin' quit\n",
            "See you later, boss\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}